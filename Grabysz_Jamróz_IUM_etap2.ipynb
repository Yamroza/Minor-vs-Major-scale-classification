{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineering\n",
    "# Project - stage II\n",
    "**Authors:**\n",
    "- Marcin Grabysz\n",
    "- Aleksandra Jamr√≥z\n",
    "\n",
    "**Task**\n",
    "\n",
    "Our song database is quite rich - they are described by many interesting parameters. Why nobody tagged if they are in major or minor scale so far? We have to change it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic model\n",
    "\n",
    "In our previous analysis we tried simple XGBoost approach. It will serve as our basic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25688 entries, 0 to 25928\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   danceability      25688 non-null  float64\n",
      " 1   energy            25688 non-null  float64\n",
      " 2   key               25688 non-null  int64  \n",
      " 3   mode              25688 non-null  float64\n",
      " 4   loudness          25688 non-null  float64\n",
      " 5   speechiness       25688 non-null  float64\n",
      " 6   acousticness      25688 non-null  float64\n",
      " 7   instrumentalness  25688 non-null  float64\n",
      " 8   liveness          25688 non-null  float64\n",
      " 9   valence           25688 non-null  float64\n",
      " 10  tempo             25688 non-null  float64\n",
      " 11  time_signature    25688 non-null  int64  \n",
      "dtypes: float64(10), int64(2)\n",
      "memory usage: 2.5 MB\n"
     ]
    }
   ],
   "source": [
    "# Data loading\n",
    "# exactly the same as in stage I\n",
    "\n",
    "df = pd.read_json(\"IUM23L_Zad_08_03_v2/tracks.jsonl\", lines=True)\n",
    "df.drop_duplicates(subset=(\"name\", \"id_artist\"), inplace=True)\n",
    "df = df.loc[df['mode'].notnull()]\n",
    "df = df.drop(columns=[\"id\", \"name\", \"popularity\", \"explicit\", \"duration_ms\", \"id_artist\", \"release_date\"])\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import sys\n",
    "\n",
    "sys.modules['sklearn.externals.joblib'] = joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.joblib import dump, load\n",
    "\n",
    "def split(df, file=None):\n",
    "    # dividing into X and y \n",
    "\n",
    "    X_final = df.drop(columns=[\"mode\"])\n",
    "    y_final = df[\"mode\"]\n",
    "\n",
    "    # scaling the data and train test split\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_final)\n",
    "    if file:\n",
    "        dump(scaler, file, compress=True)\n",
    "\n",
    "    X_scaled = scaler.transform(X_final)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_final, test_size=0.2, random_state=32)\n",
    "    return X_train, X_test, y_train, y_test, X_scaled, y_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    print(\"Accuracy: \", round(acc*100, 4), \"%\")\n",
    "    print(\"Recall: \", round(recall*100, 4), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_val_scores(model, X, y, folds=3):\n",
    "    print(\"Cross validation scores: \", cross_val_score(model, X, y, cv=folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_final, y_final = split(df, 'basic.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  69.3266 %\n",
      "Recall:  87.7375 %\n",
      "Cross validation scores:  [0.67569777 0.67896765 0.68698902]\n"
     ]
    }
   ],
   "source": [
    "xgb_tree = xgb.XGBClassifier()\n",
    "# saving basic model:\n",
    "xgb_tree.fit(X_train, y_train)\n",
    "xgb_tree.save_model('basic_model.json')\n",
    "get_scores(xgb_tree, X_train, y_train, X_test, y_test)\n",
    "get_cross_val_scores(xgb.XGBClassifier(), X_final, y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('key', 0.28115368),\n",
       " ('speechiness', 0.08026361),\n",
       " ('acousticness', 0.07867877),\n",
       " ('loudness', 0.07853775),\n",
       " ('danceability', 0.07111322),\n",
       " ('liveness', 0.07092597),\n",
       " ('mode', 0.07055699),\n",
       " ('energy', 0.07052805),\n",
       " ('valence', 0.07020085),\n",
       " ('instrumentalness', 0.06541826),\n",
       " ('tempo', 0.06262291)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature importances:\n",
    "\n",
    "sorted(\n",
    "    list(zip(df.columns, xgb_tree.feature_importances_)),\n",
    "    key=lambda t: t[1],\n",
    "    reverse=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main column having impact on our prediction is key. It is not a surprise for us, as we conducted research in the first stage of the project and expected exactly this. Rest of the columns have similar impact on the model, starting with speechiness and ending with tempo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic model - results\n",
    "\n",
    "Data preprocession for basic model was not advanced. Steps which were taken:\n",
    "- deletion of columns which we think are useless\n",
    "- data scaling.\n",
    "\n",
    "Nothing more was done. More steps will be introduced in further modelling.\n",
    "\n",
    "Highest score so far is **69,33% accuracy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced model\n",
    "\n",
    "We will try more developed approaches.\n",
    "Plans:\n",
    "- using logistic regressor instead of xgboost\n",
    "- changing class balance (making in more 50/50 between categories)\n",
    "- choosing appropriate columns\n",
    "- modyfing column structure if needed\n",
    "- hyperparameter tuning.\n",
    "\n",
    "Following cells are just some of our approaches. Including all of the attempts would take too much space and affect the clarity of the report.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  68.0226 %\n",
      "Recall:  99.4531 %\n"
     ]
    }
   ],
   "source": [
    "l_regresson = LogisticRegression()\n",
    "get_scores(l_regresson, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  68.042 %\n",
      "Recall:  99.4819 %\n"
     ]
    }
   ],
   "source": [
    "l_regresson = LogisticRegression(C = 0.5)\n",
    "get_scores(l_regresson, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  67.6139 %\n",
      "Recall:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "weights = {\n",
    "    0: 0,\n",
    "    1: 1.3\n",
    "}\n",
    "\n",
    "l_regresson = LogisticRegression(C = 0.5, class_weight=weights)\n",
    "get_scores(l_regresson, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After several experiments with following parameters:\n",
    "- penalty\n",
    "- tol\n",
    "- C\n",
    "- solver\n",
    "- warm_start\n",
    "- class_weights\n",
    "\n",
    "only changing C value had positive impact of the score. Even though, the accuracy was lower than xgboost, so we resigned from further develpoment of logistic regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing classes\n",
    "\n",
    "66% of the dataset are major tracks, while the rest (34%) are minor tracks. Those classes are unbalanced and it shows in basic approach. As we checked in previous stage (copied from the analyses):\n",
    "\n",
    "*Test set*\n",
    "\n",
    "*Major tracks in test set:  3396.0 -> Part of dataset:  66.1 %*\n",
    "\n",
    "*Minor tracks in test set:  1742.0 -> Part of dataset:  33.9 %*\n",
    "\n",
    "*Prediction*\n",
    "\n",
    "*Major tracks in prediction:  4203 -> Part of dataset:  81.8 %*\n",
    "\n",
    "*Minor tracks in prediction:  935 -> Part of dataset:  18.2 %*\n",
    "\n",
    "We can use this knowledge and try to improve the score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  69.385 %\n",
      "Recall:  88.0829 %\n"
     ]
    }
   ],
   "source": [
    "xgb_tree = xgb.XGBClassifier(scale_pos_weight = 1.01)\n",
    "get_scores(xgb_tree, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding *scale_pos_weight* parameter didn't improve the score much (0.05%). Let us try decreasing number of records of more classes in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17210 entries, 19603 to 19693\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   danceability      17210 non-null  float64\n",
      " 1   energy            17210 non-null  float64\n",
      " 2   key               17210 non-null  int64  \n",
      " 3   mode              17210 non-null  float64\n",
      " 4   loudness          17210 non-null  float64\n",
      " 5   speechiness       17210 non-null  float64\n",
      " 6   acousticness      17210 non-null  float64\n",
      " 7   instrumentalness  17210 non-null  float64\n",
      " 8   liveness          17210 non-null  float64\n",
      " 9   valence           17210 non-null  float64\n",
      " 10  tempo             17210 non-null  float64\n",
      " 11  time_signature    17210 non-null  int64  \n",
      "dtypes: float64(10), int64(2)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_0 = df[df['mode'] == 0]\n",
    "df_1 = df[df['mode'] == 1]\n",
    "diff = len(df_1.index) - len(df_0.index)\n",
    "df_1 = df_1.sample(frac=1).iloc[diff:]\n",
    "df_conc = pd.concat([df_1, df_0])\n",
    "df_conc = df_conc.sample(frac=1)\n",
    "df_conc.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  60.4881 %\n",
      "Recall:  61.421 %\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_final, y_final = split(df_conc)\n",
    "\n",
    "xgb_tree = xgb.XGBClassifier()\n",
    "get_scores(xgb_tree, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you can see here is balancing the classes manually. In our case this move drastically decreased number of instances in the dataset. Client provided this dataset and no more rows are available, so we can't increase its size by loading more data. Cutting random rows to make number of instances of each class equal resulted with much smaller dataset, which was not enough for the model to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing 'key' column structure\n",
    "\n",
    "Key column is now a numeric column. It shouldn't - key values are not linear and we can't sort them. First approach would be to create dummies out of this column.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  69.0152 %\n",
      "Recall:  87.3921 %\n"
     ]
    }
   ],
   "source": [
    "df_dummies = pd.get_dummies(df, columns=['key'])\n",
    "X_train, X_test, y_train, y_test, X_final, y_final = split(df_dummies)\n",
    "xgb_tree = xgb.XGBClassifier()\n",
    "get_scores(xgb_tree, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 12 different key values. It is not a small number, so our model doesn't cope with this type of data better than the standard one. We will try a different idea. We will change 'key' value to truly linear form. We will sort the keys by balance between minor and major tracks appearing in exact key. We hope that will affect our model to differentiate between keys containing more minor than major instances from those which contain a reversed balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F#</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>C#</th>\n",
       "      <th>A#</th>\n",
       "      <th>G#</th>\n",
       "      <th>E</th>\n",
       "      <th>G</th>\n",
       "      <th>B</th>\n",
       "      <th>A</th>\n",
       "      <th>F</th>\n",
       "      <th>D#</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>major</th>\n",
       "      <td>616.000000</td>\n",
       "      <td>2630.000000</td>\n",
       "      <td>2252.000000</td>\n",
       "      <td>1182.00000</td>\n",
       "      <td>938.000000</td>\n",
       "      <td>1162.00000</td>\n",
       "      <td>1081.000000</td>\n",
       "      <td>2552.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>1918.000000</td>\n",
       "      <td>1418.000000</td>\n",
       "      <td>653.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minor</th>\n",
       "      <td>639.000000</td>\n",
       "      <td>691.000000</td>\n",
       "      <td>722.000000</td>\n",
       "      <td>539.00000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>287.00000</td>\n",
       "      <td>1135.000000</td>\n",
       "      <td>724.000000</td>\n",
       "      <td>1021.000000</td>\n",
       "      <td>1169.000000</td>\n",
       "      <td>852.000000</td>\n",
       "      <td>234.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>0.964006</td>\n",
       "      <td>3.806078</td>\n",
       "      <td>3.119114</td>\n",
       "      <td>2.19295</td>\n",
       "      <td>1.584459</td>\n",
       "      <td>4.04878</td>\n",
       "      <td>0.952423</td>\n",
       "      <td>3.524862</td>\n",
       "      <td>0.666993</td>\n",
       "      <td>1.640719</td>\n",
       "      <td>1.664319</td>\n",
       "      <td>2.790598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 F#            C            D          C#          A#  \\\n",
       "major    616.000000  2630.000000  2252.000000  1182.00000  938.000000   \n",
       "minor    639.000000   691.000000   722.000000   539.00000  592.000000   \n",
       "balance    0.964006     3.806078     3.119114     2.19295    1.584459   \n",
       "\n",
       "                 G#            E            G            B            A  \\\n",
       "major    1162.00000  1081.000000  2552.000000   681.000000  1918.000000   \n",
       "minor     287.00000  1135.000000   724.000000  1021.000000  1169.000000   \n",
       "balance     4.04878     0.952423     3.524862     0.666993     1.640719   \n",
       "\n",
       "                   F          D#  \n",
       "major    1418.000000  653.000000  \n",
       "minor     852.000000  234.000000  \n",
       "balance     1.664319    2.790598  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_dict = {0: \"C\", 1: \"C#\", 2: \"D\", 3: \"D#\", 4: \"E\", 5: \"F\", 6: \"F#\", 7: \"G\", 8: \"G#\", 9: \"A\", 10: \"A#\", 11: \"B\"}\n",
    "df[\"key\"].replace(letter_dict, inplace=True)\n",
    "\n",
    "def get_keys_mode_df():\n",
    "    keys_dict = {}\n",
    "    for index, row in df[[\"key\", \"mode\"]].iterrows():\n",
    "        if row[\"key\"] not in keys_dict.keys():\n",
    "            keys_dict[row[\"key\"]] = {\"major\": 0, \"minor\": 0, \"balance\": 0}\n",
    "        if row[\"mode\"] == 0:\n",
    "            keys_dict[row[\"key\"]][\"minor\"] += 1\n",
    "        if row[\"mode\"] == 1:\n",
    "            keys_dict[row[\"key\"]][\"major\"] += 1\n",
    "    for key in keys_dict:\n",
    "        keys_dict[key]['balance'] = keys_dict[key]['major'] / keys_dict[key]['minor'] \n",
    "    return pd.DataFrame.from_dict(keys_dict), keys_dict\n",
    "\n",
    "df_key, keys_dict = get_keys_mode_df()\n",
    "df_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B', 0.6669931439764937),\n",
       " ('E', 0.9524229074889868),\n",
       " ('F#', 0.9640062597809077),\n",
       " ('A#', 1.5844594594594594),\n",
       " ('A', 1.6407185628742516),\n",
       " ('F', 1.664319248826291),\n",
       " ('C#', 2.1929499072356213),\n",
       " ('D#', 2.7905982905982905),\n",
       " ('D', 3.119113573407202),\n",
       " ('G', 3.5248618784530388),\n",
       " ('C', 3.806078147612156),\n",
       " ('G#', 4.048780487804878)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "keys = []\n",
    "balances = []\n",
    "for key in keys_dict:\n",
    "    keys.append(key)\n",
    "    balances.append(keys_dict[key]['balance'])\n",
    "\n",
    "sorted_keys = sorted(\n",
    "    list(zip(keys, balances)),\n",
    "    key=lambda t: t[1]\n",
    ")\n",
    "\n",
    "sorted_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': 0, 'E': 1, 'F#': 2, 'A#': 3, 'A': 4, 'F': 5, 'C#': 6, 'D#': 7, 'D': 8, 'G': 9, 'C': 10, 'G#': 11}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "changing_dict = {}\n",
    "for index, pair in enumerate(sorted_keys):\n",
    "    changing_dict[pair[0]] = index\n",
    "print(changing_dict)\n",
    "\n",
    "df[\"key\"].replace(changing_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  68.4897 %\n",
      "Recall:  86.3846 %\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_final, y_final = split(df, 'advanced.bin')\n",
    "xgb_tree = xgb.XGBClassifier()\n",
    "get_scores(xgb_tree, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hoped that this operation will bring improvement. As we can observe, score is quite similar to previous ones. We decided keep it for further development anyway. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters tuning\n",
    "\n",
    "This part is our main field for improvemt. We will try to get most of our data by changing values of the parameters. Considering tiny amount of time that xgboost needed for training, we conducted a lot of experiments changing parameters manually, seeking for best ones. Example below shows ranges between which we searched for optimal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_estimators:  1\n",
      "Learning rate:  0.01\n",
      "Accuracy:  69.6185 %\n",
      "Recall:  91.1054 %\n",
      "\n",
      "N_estimators:  20\n",
      "Learning rate:  0.03\n",
      "Accuracy:  70.2024 %\n",
      "Recall:  91.1341 %\n",
      "\n",
      "N_estimators:  50\n",
      "Learning rate:  0.05\n",
      "Accuracy:  70.6111 %\n",
      "Recall:  91.422 %\n",
      "\n",
      "N_estimators:  90\n",
      "Learning rate:  0.1\n",
      "Accuracy:  70.7474 %\n",
      "Recall:  91.019 %\n",
      "\n",
      "N_estimators:  120\n",
      "Learning rate:  0.3\n",
      "Accuracy:  68.3534 %\n",
      "Recall:  86.1255 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_estimators_n = [1, 20, 50, 90, 120]\n",
    "learning_rates = [0.01, 0.03, 0.05, 0.1, 0.3, 0.7]\n",
    "\n",
    "for n_estimator, learning_rate in zip(n_estimators_n, learning_rates):\n",
    "    xgb_tree = xgb.XGBClassifier(\n",
    "        n_estimators = n_estimator,\n",
    "        learning_rate = learning_rate\n",
    "    )\n",
    "    print(\"N_estimators: \", n_estimator)\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    get_scores(xgb_tree, X_train, y_train, X_test, y_test)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best params chosen:\n",
    "- n_estimators: 90\n",
    "- learning rate: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the model\n",
    "\n",
    "No matter what we did, our score didn't improve too much, that's why we decided to try a different model. Decision was made to choose SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  70.1051 %\n",
      "Recall:  95.1065 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "get_scores(svc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appeared, that using SVC result with better basic accuracy and overall it didn't differ much from XGBoost. Disadvantage of this model is time needed to train it - while XGBoost Classifier needs maximum of 1.5 seconds to learn, SVC needs around 30. That's why our final model will be XGBoost with parameters chosen earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  0.01  Degree:  2\n",
      "Accuracy:  67.6139 %\n",
      "Recall:  100.0 %\n",
      "\n",
      "C:  0.01  Degree:  3\n",
      "Accuracy:  67.6139 %\n",
      "Recall:  100.0 %\n",
      "\n",
      "C:  1  Degree:  2\n",
      "Accuracy:  70.1051 %\n",
      "Recall:  95.1065 %\n",
      "\n",
      "C:  1  Degree:  3\n",
      "Accuracy:  70.1051 %\n",
      "Recall:  95.1065 %\n",
      "\n",
      "C:  10  Degree:  2\n",
      "Accuracy:  69.7937 %\n",
      "Recall:  92.228 %\n",
      "\n",
      "C:  10  Degree:  3\n",
      "Accuracy:  69.7937 %\n",
      "Recall:  92.228 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cs = [0.01, 1, 10]\n",
    "degrees = [2, 3]\n",
    "for c in cs:\n",
    "    for d in degrees:\n",
    "        svc = SVC(C=c, degree=d)\n",
    "        print(\"C: \", c, \" Degree: \", d)\n",
    "        get_scores(svc, X_train, y_train, X_test, y_test)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  70.7474 %\n",
      "Recall:  91.019 %\n",
      "Cross validation scores:  [0.68956793 0.69540677 0.6969638  0.69398482 0.69807281]\n"
     ]
    }
   ],
   "source": [
    "final_model = xgb.XGBClassifier(\n",
    "        n_estimators = 90,\n",
    "        learning_rate = 0.1\n",
    "    )\n",
    "\n",
    "get_scores(xgb.XGBClassifier(n_estimators = 90, learning_rate = 0.1), X_train, y_train, X_test, y_test)\n",
    "get_cross_val_scores(xgb.XGBClassifier(n_estimators = 90, learning_rate = 0.1), X_final, y_final, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.fit(X_train, y_train)\n",
    "final_model.save_model(\"advanced_model.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal of obtaining 70% accuracy is accomplished by using this hyperparameter set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Service\n",
    "\n",
    "In order to make the predictions easily available, we implemented a simple service in REST methodology using Python Fastapi library. Since the project serves for academic purposes, the application was run and tested only locally; however, if we were to share our models to a wider public, we could easily deploy the service on a virtual machine in a cloud.\n",
    "\n",
    "### Instruction\n",
    "\n",
    "Complete implementation of the REST service can be found in Python Package `server` in our project. To run application locally, make sure you have installed all the packages from `requirements.txt` on your local environment and run module `server.py`\n",
    "```\n",
    "python3 server/server.py \n",
    "```\n",
    "The server exposes two POST methods on the port 8000 of localhost:\n",
    "* `http://localhost:8000/basic/mode` - to predict the mode attribute using the basic model\n",
    "* `http://localhost:8000/advanced/mode` - to predict the mode attribute using the advanced model\n",
    "\n",
    "Each of the methods requires a body in `json` format containing features of the track to generate prediction for. Example can be found below:\n",
    "\n",
    "**Raw request body in json format**\n",
    "```\n",
    "{\n",
    "  \"id\": \"7HysCKp2SSh6LvLkcuJQkB\",\n",
    "  \"name\": \"Wie weit wir gehen\",\n",
    "  \"popularity\": 49,\n",
    "  \"duration_ms\": 179347,\n",
    "  \"explicit\": 0,\n",
    "  \"id_artist\": \"2C7RDMSpyGZFyoSnvOeU4J\",\n",
    "  \"release_date\": \"2011-06-10\",\n",
    "  \"danceability\": 0.506,\n",
    "  \"energy\": 0.828,\n",
    "  \"key\": 6,\n",
    "  \"loudness\": -2.868,\n",
    "  \"speechiness\": 0.0312,\n",
    "  \"acousticness\": 0.0452,\n",
    "  \"instrumentalness\": 0.0,\n",
    "  \"liveness\": 0.206,\n",
    "  \"valence\": 0.784,\n",
    "  \"tempo\": 179.989,\n",
    "  \"time_signature\": 4\n",
    "}\n",
    "```\n",
    "\n",
    "**Complete example of request body and response to the REST client (Talend API Tester)**\n",
    "![](images/api_response.png)\n",
    "\n",
    "### Testing\n",
    "\n",
    "Exposing endpoints with generated predictions makes possible to test the models with A/B testing. We evaluate two mutually exclusive hypothesis:\n",
    "* *H1* - the advanced model is **not** better then the basic model\n",
    "* *H2* - the advanced model is better then the basic model\n",
    "\n",
    "To evaluate the models quality we use student's t statistic calculated using the `scipy` package.\n",
    "\n",
    "The code below executes the following steps:\n",
    "* retrieve two exclusive samples of tracks which mode is known\n",
    "* test the basic model on the first sample: prepare a list of guesses, where guess equals 1 if prediction was correct and 0 otherwise\n",
    "* test the advanced model on the second sample in an analogical way\n",
    "\n",
    "**Important:** to run the tests, the server must be on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import t\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Data loading\n",
    "\n",
    "SAMPLE_SIZE = 1000\n",
    "BASIC_MODEL_URL = \"http://localhost:8000/basic/mode\"\n",
    "ADVANCED_MODEL_URL = \"http://localhost:8000/advanced/mode\"\n",
    "\n",
    "df = pd.read_json(\"IUM23L_Zad_08_03_v2/tracks.jsonl\", lines=True)\n",
    "df.drop_duplicates(subset=(\"name\", \"id_artist\"), inplace=True)\n",
    "df = df.loc[df['mode'].notnull()]\n",
    "df = df.sample(n=SAMPLE_SIZE*2)\n",
    "sample_one = df.iloc[SAMPLE_SIZE:, :]\n",
    "sample_two = df.iloc[:SAMPLE_SIZE, :]\n",
    "\n",
    "# Testing\n",
    "\n",
    "basic_model_guesses = []\n",
    "for i in range(len(sample_one)):\n",
    "    track = sample_one.iloc[i].squeeze().to_dict()   # retrieve track in json format\n",
    "    correct_mode = track.pop(\"mode\")                 # save the correct mode and remove it from json\n",
    "    predicted_mode = requests.post(BASIC_MODEL_URL, json=track).json()[\"mode\"]\n",
    "    guess = 1 if predicted_mode == correct_mode else 0\n",
    "    basic_model_guesses.append(guess)\n",
    "    \n",
    "advanced_model_guesses = []\n",
    "for i in range(len(sample_two)):\n",
    "    track = sample_two.iloc[i].squeeze().to_dict()   # retrieve track in json format\n",
    "    correct_mode = track.pop(\"mode\")                 # save the correct mode and remove it from json\n",
    "    predicted_mode = requests.post(ADVANCED_MODEL_URL, json=track).json()[\"mode\"]\n",
    "    guess = 1 if predicted_mode == correct_mode else 0\n",
    "    advanced_model_guesses.append(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-student statistic: 4.927203339931512\n",
      "p-value: 9.02810683542512e-07\n"
     ]
    }
   ],
   "source": [
    "statistic, pvalue = ttest_ind(advanced_model_guesses, basic_model_guesses)\n",
    "\n",
    "print(f\"t-student statistic: {statistic}\")\n",
    "print(f\"p-value: {pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic model accuracy: 0.619\n",
      "Advanced model accuracy: 0.722\n"
     ]
    }
   ],
   "source": [
    "basic_model_accuracy = basic_model_guesses.count(1) / len(basic_model_guesses)\n",
    "advanced_model_accuracy = advanced_model_guesses.count(1) / len(advanced_model_guesses)\n",
    "\n",
    "print(f\"Basic model accuracy: {basic_model_accuracy}\")\n",
    "print(f\"Advanced model accuracy: {advanced_model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test result interpretation\n",
    "Obtained statistic confirms that the advanced model is better than the basic model. Moreover, calculated *p-value* is very small (significantly smaller than the standard significance level $\\alpha$, equal 0.005); this assures us that obtained result is not a matter of chance.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
